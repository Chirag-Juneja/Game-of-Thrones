{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17c25125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b593db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = os.listdir('data')\n",
    "text=\"\"\n",
    "for book in books[:]:\n",
    "    with open(f\"data/{book}\", 'r') as file:\n",
    "        text = text + file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd3cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = text.split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fdd1304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3430"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0525bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4473"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max(pages,key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b3043fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2846.140524781341"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(page) for page in pages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a557210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"T\"It was Jory,\" his steward Vayon Poole replied. \"She\\'s not been harmed.\" \\n\"Thank the gods,\" Ned said. His men had been searching for Arya for four days now, but the queen\\'s \\nmen had been out hunting as well. \"Where is she? Tell Jory to bring her here at once.\" \\n\"I am sorry, my lord,\" Poole told him. \"The guards on the gate were Lannister men, and they informed \\nthe queen when Jory brought her in. She\\'s being taken directly before the king . . .\" \\n\"Damn that woman!\" Ned said, striding to the door. \"Find Sansa and bring her to the audience chamber. \\nHer voice may be needed.\" He descended the tower steps in a red rage. He had led searches himself for \\nthe first three days, and had scarcely slept an hour since Arya had disappeared. This morning he had \\nbeen so heartsick and weary he could scarcely stand, but now his fury was on him, filling him with \\nstrength. \\nMen called out to him as he crossed the castle yard, but Ned ignored them in his haste. He would have \\nrun, but he was still the King\\'s Hand, and a Hand must keep his dignity. He was aware of the eyes that \\nfollowed him, of the muttered voices wondering what he would do. \\nThe castle was a modest holding a half day\\'s ride south of the Trident. The royal party had made \\nthemselves the uninvited guests of its lord, Ser Raymun Darry, while the hunt for Arya and the butcher\\'s \\nboy was conducted on both sides of the river. They were not welcome visitors. Ser Raymun lived under \\nthe king\\'s peace, but his family had fought beneath Rhaegar\\'s dragon banners at the Trident, and his three \\nolder brothers had died there, a truth neither Robert nor Ser Raymun had forgotten. With king\\'s men, \\nDarry men, Lannister men, and Stark men all crammed into a castle far too small for them, tensions \\nburned hot and heavy. \\nThe king had appropriated Ser Raymun\\'s audience chamber, and that was where Ned found them. The \\nroom was crowded when he burst in. Too crowded, he thought; left alone, he and Robert might have \\nbeen able to settle the matter amicably. \\nRobert was slumped in Darry\\'s high seat at the far end of the room, his face closed and sullen. Cersei \\nLannister and her son stood beside him. The queen had her hand on Joffrey\\'s shoulder. Thick silken \\nbandages still covered the boy\\'s arm. \\nArya stood in the center of the room, alone but for Jory Cassel, every eye upon her. \"Arya,\" Ned called \\nloudly. He went to her, his boots ringing on the stone floor. When she saw him, she cried out and began \\nto sob. \\nNed went to one knee and took her in his arms. She was shaking. \"I\\'m sorry,\" she sobbed, \"I\\'m sorry, \\nI\\'m sorry.\" \\n\"I know,\" he said. She felt so tiny in his arms, nothing but a scrawny little girl. It was hard to see how she \\nhad caused so much trouble. \"Are you hurt?\" \\n\"No.\" Her face was dirty, and her tears left pink tracks down her cheeks. \"Hungry some. I ate some \\nberries, but there was nothing else.\" \\n\"We\\'ll feed you soon enough,\" Ned promised. He rose to face the king. \"What is the meaning of this?\" \\nPage 101'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82efdc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23c81d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9769120"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f66b2cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 94\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(f\"vocab size: {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4dbb0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = preprocessing.StringLookup(\n",
    "    vocabulary=list(vocab),\n",
    "    mask_token=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8de0b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_from_ids = preprocessing.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(),\n",
    "    invert=True,\n",
    "    mask_token=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63e11cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'G' b'a' b'r' b'e' b'd' b' ' b'u' b'r' b'g' b'e' b'd' b' ' b'a' b's'\n",
      " b' ' b't' b'h' b'e' b' ' b'w' b'o' b'o' b'd' b's' b' ' b'b' b'e' b'g'\n",
      " b'a' b'n' b' ' b't' b'o' b' ' b'g' b'r' b'o' b'w' b' ' b'd' b'a' b'r'\n",
      " b'k' b' ' b'a' b'r' b'o' b'u' b'n' b'd' b' ' b't' b'h' b'e' b'm' b'.'], shape=(56,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "s = \"Gared urged as the woods began to grow dark around them.\"\n",
    "chars = tf.strings.unicode_split(s,input_encoding=\"UTF-8\")\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e435a9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[33 57 74 61 60  1 77 74 63 61 60  1 57 75  1 76 64 61  1 79 71 71 60 75\n",
      "  1 58 61 63 57 70  1 76 71  1 63 74 71 79  1 60 57 74 67  1 57 74 71 77\n",
      " 70 60  1 76 64 61 69 12], shape=(56,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e809754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'G' b'a' b'r' b'e' b'd' b' ' b'u' b'r' b'g' b'e' b'd' b' ' b'a' b's'\n",
      " b' ' b't' b'h' b'e' b' ' b'w' b'o' b'o' b'd' b's' b' ' b'b' b'e' b'g'\n",
      " b'a' b'n' b' ' b't' b'o' b' ' b'g' b'r' b'o' b'w' b' ' b'd' b'a' b'r'\n",
      " b'k' b' ' b'a' b'r' b'o' b'u' b'n' b'd' b' ' b't' b'h' b'e' b'm' b'.'], shape=(56,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "chars = chars_from_ids(ids)\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efff798c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Gared urged as the woods began to grow dark around them.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join(chars,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05d03ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "953385a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ids = ids_from_chars(tf.strings.unicode_split(text,input_encoding=\"UTF-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3af67653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([9769120])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d6dece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(text_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a33125fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 512\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01bb7840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c323cc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a69abb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  b'PROLOGUE  \"We should start back,\" Gared urged as the woods began to grow dark around them. \"The wildlings are  dead.\"  \"Do the dead frighten you?\" Ser Waymar Royce asked with just the hint of a smile.  Gared did not rise to the bait. He was an old man, past fifty, and he had seen the lordlings come and go.  \"Dead is dead,\" he said. \"We have no business with the dead.\"  \"Are they dead?\" Royce asked softly. \"What proof have we?\"  \"Will saw them,\" Gared said. \"If he says they are dead, that\\'s proof enough for '\n",
      "Target:  b'ROLOGUE  \"We should start back,\" Gared urged as the woods began to grow dark around them. \"The wildlings are  dead.\"  \"Do the dead frighten you?\" Ser Waymar Royce asked with just the hint of a smile.  Gared did not rise to the bait. He was an old man, past fifty, and he had seen the lordlings come and go.  \"Dead is dead,\" he said. \"We have no business with the dead.\"  \"Are they dead?\" Royce asked softly. \"What proof have we?\"  \"Will saw them,\" Gared said. \"If he says they are dead, that\\'s proof enough for m'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input: \",text_from_ids(input_example).numpy())\n",
    "    print(\"Target: \",text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "706a50a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((128, 512), (128, 512)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "778c5484",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce14b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGeneration(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c9b6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextGeneration(vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "                       embedding_dim=embedding_dim,\n",
    "                       rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1325a0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d8c8f3",
   "metadata": {},
   "source": [
    "### Check Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd75b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir,\"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce76aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "defbc11a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "148/148 [==============================] - 194s 1s/step - loss: 3.2745\n",
      "Epoch 2/20\n",
      "148/148 [==============================] - 191s 1s/step - loss: 2.1986\n",
      "Epoch 3/20\n",
      "148/148 [==============================] - 190s 1s/step - loss: 1.8952\n",
      "Epoch 4/20\n",
      "148/148 [==============================] - 190s 1s/step - loss: 1.6613\n",
      "Epoch 5/20\n",
      "148/148 [==============================] - 190s 1s/step - loss: 1.5077\n",
      "Epoch 6/20\n",
      "148/148 [==============================] - 189s 1s/step - loss: 1.4180\n",
      "Epoch 7/20\n",
      "148/148 [==============================] - 189s 1s/step - loss: 1.3577\n",
      "Epoch 8/20\n",
      "148/148 [==============================] - 190s 1s/step - loss: 1.3173\n",
      "Epoch 9/20\n",
      "148/148 [==============================] - 191s 1s/step - loss: 1.2902\n",
      "Epoch 10/20\n",
      "148/148 [==============================] - 191s 1s/step - loss: 1.2661\n",
      "Epoch 11/20\n",
      "148/148 [==============================] - 192s 1s/step - loss: 1.2451\n",
      "Epoch 12/20\n",
      "148/148 [==============================] - 196s 1s/step - loss: 1.2293\n",
      "Epoch 13/20\n",
      "148/148 [==============================] - 194s 1s/step - loss: 1.2171\n",
      "Epoch 14/20\n",
      "148/148 [==============================] - 195s 1s/step - loss: 1.2036\n",
      "Epoch 15/20\n",
      "148/148 [==============================] - 192s 1s/step - loss: 1.1936\n",
      "Epoch 16/20\n",
      "148/148 [==============================] - 195s 1s/step - loss: 1.1837\n",
      "Epoch 17/20\n",
      "148/148 [==============================] - 195s 1s/step - loss: 1.1747\n",
      "Epoch 18/20\n",
      "148/148 [==============================] - 193s 1s/step - loss: 1.1678\n",
      "Epoch 19/20\n",
      "148/148 [==============================] - 191s 1s/step - loss: 1.1595\n",
      "Epoch 20/20\n",
      "148/148 [==============================] - 191s 1s/step - loss: 1.1534\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eae29dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "        skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            values=[-float('inf')]*len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        \n",
    "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "        predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "        \n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits/self.temperature\n",
    "        \n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "        \n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "        \n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "        return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd2063ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "232ae41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jon agreed. Those are horses and I would not  eat the loose of the other Landing? Yet they were owh if I drew some line. He saw a bull in hobbing, \"I'm not condemned, and that will have  a farpetifice alone. Certain of your head,\" said Late. The Light-gave again, even Halfmaer’s son. The Old Tongue did have  the clothing as it think. Their out the dirt and the cages. How long home, nor to stop his.  The second friend, he thinks  of our trees say, and Bronn brings the greatsword feral want, a goodfrey in the ships too. What afternoon was  she'd best be boiling into fiery liege  lot at each pity. All turn to the clanks, Dany thought.  And it is still apart. The  knight belonged a hundred Prince Column and Dulk, the man no more to be able. The crown had  had the fellow. This settling throble greater had supposed to be a baly from hip.  When he was made a dozen Dany thought, squeal, Janos Wylts.  “Trusted that too my widow, and some rankled sigil of your father, Lord Snow?” avoid  on a few wh \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time:  3.0852270126342773\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['Jon'])\n",
    "results = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    results.append(next_char)\n",
    "\n",
    "results = tf.strings.join(results)\n",
    "end = time.time()\n",
    "print(results[0].numpy().decode(\"utf-8\"), \"\\n\\n\"+ \"_\"*80)\n",
    "print(\"\\nRun time: \", end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
